Due to GitHub data upload limit I am not able to upload the training data as well pre-trained models into this repository. So before running the following python codes download the data files from this link : https://drive.google.com/open?id=1lqBBljwO9MFun82rPi2MsO3TQJ5EZM9o  .Then extract the data files into your current working folder.

Use Tensorflow version 1.1 only

Use sentiment.py to train the model, and it gets saved in "models" folder.
Use predict.py to load the pre-trained model from "models1" folder which we trained by making around 1,10,000 iterations.
